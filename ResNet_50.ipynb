{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himanshu11081999/ResNet-50/blob/main/ResNet_50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Install necessary libraries if not already present\n",
        "!pip install torch torchvision scikit-learn kagglehub\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOeRSadUMIuv",
        "outputId": "b878c055-54e9-4b95-eb1a-42738af97f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting medmnist\n",
            "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from medmnist) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from medmnist) (11.2.1)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.21.0+cu124)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->medmnist) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2025.5.21)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (4.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n",
            "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=e56cc26c3fe74ab9f8c11d00f67deb20bf9d91c6fc0b57273d0e9e5ec17c01fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.7.0 medmnist-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "!pip install medmnist\n",
        "# %%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evMZNIijuN1x",
        "outputId": "4951492b-94a3-420a-9b7a-7aa5f358e4cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: medmnist in /usr/local/lib/python3.11/dist-packages (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from medmnist) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from medmnist) (11.2.1)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.21.0+cu124)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->medmnist) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2025.5.21)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (4.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import os\n",
        "import shutil # Import shutil for removing directories\n",
        "import tarfile # Import tarfile for extracting .tar.gz files\n",
        "import kagglehub # Import kagglehub for dataset download\n",
        "import medmnist # Import medmnist\n",
        "from medmnist.dataset import PneumoniaMNIST # Import the specific dataset class\n"
      ],
      "metadata": {
        "id": "6tiTyJk1FoNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dataset: PneumoniaMNIST\n",
        "# Using kagglehub to download the dataset\n",
        "\n",
        "# Define the target data directory where you want the data to reside\n",
        "data_dir = 'data/pneumoniamnist'\n",
        "dataset_file_name = 'pneumoniamnist.npz' # Expecting .npz file now\n",
        "downloaded_npz_path = os.path.join(data_dir, dataset_file_name) # Define the path for the .npz file\n",
        "\n",
        "# Check if the data directory already exists and contains data\n",
        "# Check for the existence of the .npz file within the target data_dir\n",
        "# Note: medmnist expects the .npz file in the root directory *before* processing.\n",
        "# It then extracts/loads from this .npz into memory or potentially other files\n",
        "# depending on the dataset.\n",
        "if not os.path.exists(downloaded_npz_path):\n",
        "    print(f\"Dataset not found in {data_dir}. Downloading using kagglehub...\")\n",
        "\n",
        "    try:\n",
        "        # Download the dataset using kagglehub.\n",
        "        # This downloads the dataset files to a cache location.\n",
        "        # The path returned is the root directory of the downloaded files in the cache.\n",
        "        kaggle_download_root = kagglehub.dataset_download(\"rijulshr/pneumoniamnist\")\n",
        "        print(f\"Kaggle dataset downloaded to cache: {kaggle_download_root}\")\n",
        "\n",
        "        # Locate the expected .npz file within the downloaded directory.\n",
        "        downloaded_source_npz_path = os.path.join(kaggle_download_root, dataset_file_name)\n",
        "\n",
        "\n",
        "        # Check if the expected .npz file exists in the downloaded path\n",
        "        if not os.path.exists(downloaded_source_npz_path):\n",
        "            print(f\"Error: Expected file {dataset_file_name} not found in the Kaggle download path: {kaggle_download_root}\")\n",
        "            print(\"Please check the contents of the downloaded dataset on Kaggle or inspect the downloaded path.\")\n",
        "            # Optionally, list files in the downloaded directory for inspection\n",
        "            print(\"Files found in downloaded directory:\")\n",
        "            for root, dirs, files in os.walk(kaggle_download_root):\n",
        "                level = root.replace(kaggle_download_root, '').count(os.sep)\n",
        "                indent = ' ' * 4 * (level)\n",
        "                print(f'{indent}{os.path.basename(root)}/')\n",
        "                subindent = ' ' * 4 * (level + 1)\n",
        "                for f in files:\n",
        "                    print(f'{subindent}{f}')\n",
        "            raise FileNotFoundError(f\"{dataset_file_name} not found in {kaggle_download_root}\")\n",
        "\n",
        "        print(f\"Found dataset npz file at: {downloaded_source_npz_path}\")\n",
        "\n",
        "        # Create the target data directory if it doesn't exist\n",
        "        os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "        # **Changed:** Use shutil.copy2 instead of shutil.move\n",
        "        # shutil.move attempts to delete the source file, which is not allowed in read-only /kaggle/input\n",
        "        # shutil.copy2 copies the file metadata as well, which is generally preferred over shutil.copy\n",
        "        print(f\"Copying {downloaded_source_npz_path} to {downloaded_npz_path}\")\n",
        "        shutil.copy2(downloaded_source_npz_path, downloaded_npz_path)\n",
        "        print(\"Copy complete.\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during kagglehub download or processing: {e}\")\n",
        "        raise # Re-raise the exception\n",
        "\n",
        "else:\n",
        "    print(f\"Dataset already found in {downloaded_npz_path}. Skipping download.\")\n",
        "\n",
        "\n",
        "# Transforms\n",
        "# MedMNIST datasets are typically grayscale (1 channel). Normalize accordingly.\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(), # Converts PIL Image to Tensor (H x W x C) to (C x H x W) and scales pixels to [0, 1]\n",
        "        transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0) == 1 else x), # Convert grayscale to 3 channels if needed by the model\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet normalization\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0) == 1 else x), # Convert grayscale to 3 channels if needed by the model\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet normalization\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0) == 1 else x), # Convert grayscale to 3 channels if needed by the model\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet normalization\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Load the datasets using medmnist\n",
        "# PneumoniaMNIST is dataset index 5 in medmnist v2\n",
        "# DataClass = medmnist.INFO['pneumoniamnist']['python_class'] # This returns the class NAME as a string\n",
        "DataClass = PneumoniaMNIST # Assign the imported class to DataClass\n",
        "\n",
        "info = medmnist.INFO['pneumoniamnist']\n",
        "num_classes = len(info['label']) # Get the number of classes from the medmnist info\n",
        "\n",
        "# **FIX:** Create a dummy instance to trigger medmnist's internal loading/processing\n",
        "# from the .npz file we've placed in data_dir.\n",
        "# This only needs to be done once. Subsequent dataset instances will find the processed data.\n",
        "# We pass a basic transform as the actual transforms will be applied later.\n",
        "# Set download=True to trigger the loading/processing logic if the processed data isn't found.\n",
        "print(\"Checking and processing dataset files with medmnist (if necessary)...\")\n",
        "# Use a simple transform for this initial load if transforms are required by the constructor\n",
        "# otherwise, None might suffice depending on the medmnist version/dataset\n",
        "initial_transform = transforms.Compose([transforms.ToTensor()]) # Use a minimal transform\n",
        "_ = DataClass(split='train', transform=initial_transform, download=True, root=data_dir)\n",
        "print(\"Medmnist processing check complete.\")\n",
        "\n",
        "\n",
        "# Now load the actual datasets for training, validation, and testing\n",
        "# Set download=False as the data should now be processed and available in data_dir\n",
        "train_dataset = DataClass(split='train', transform=data_transforms['train'], download=False, root=data_dir)\n",
        "val_dataset = DataClass(split='val', transform=data_transforms['val'], download=False, root=data_dir)\n",
        "test_dataset = DataClass(split='test', transform=data_transforms['test'], download=False, root=data_dir)\n",
        "\n",
        "\n",
        "# Print dataset sizes and class names for verification\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "# MedMNIST datasets provide label information in the INFO dictionary\n",
        "print(f\"Classes: {list(info['label'].values())}\")\n",
        "print(f\"Class to index mapping: {info['label']}\")\n",
        "\n",
        "\n",
        "# Data Loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) # Add a loader for the test set\n",
        "\n",
        "# Load pretrained ResNet50\n",
        "# Using weights=ResNet50_Weights.DEFAULT is the modern way to load default weights\n",
        "# You need to import ResNet50_Weights\n",
        "from torchvision.models import ResNet50_Weights\n",
        "# ResNet50 expects 3 input channels, we've handled this in the transforms\n",
        "model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "\n",
        "# Freeze all layers except the final fully connected layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the final fully connected layer\n",
        "# The number of output features should match the number of classes in your dataset.\n",
        "# num_classes is already defined from medmnist info\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Fine-tuning\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Only optimize the parameters of the newly added final layer\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSGYXKffHYpt",
        "outputId": "704a6cc6-0e1e-4e23-975e-90146aa682ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset not found in data/pneumoniamnist. Downloading using kagglehub...\n",
            "Kaggle dataset downloaded to cache: /kaggle/input/pneumoniamnist\n",
            "Found dataset npz file at: /kaggle/input/pneumoniamnist/pneumoniamnist.npz\n",
            "Copying /kaggle/input/pneumoniamnist/pneumoniamnist.npz to data/pneumoniamnist/pneumoniamnist.npz\n",
            "Copy complete.\n",
            "Checking and processing dataset files with medmnist (if necessary)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.17M/4.17M [00:04<00:00, 857kB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Medmnist processing check complete.\n",
            "Train dataset size: 4708\n",
            "Validation dataset size: 524\n",
            "Test dataset size: 624\n",
            "Classes: ['normal', 'pneumonia']\n",
            "Class to index mapping: {'0': 'normal', '1': 'pneumonia'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 162MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "num_epochs = 5 # Define the number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    # Ensure the cell defining 'model' has been run before this cell\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        # Move data to device (GPU or CPU)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Squeeze the labels tensor to remove the extra dimension if it exists\n",
        "        # CrossEntropyLoss expects target shape (batch_size,)\n",
        "        if labels.ndim > 1 and labels.size(-1) == 1:\n",
        "            labels = labels.squeeze(-1)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = correct_train / total_train\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.4f}\")"
      ],
      "metadata": {
        "id": "Ks7-9yFGEhYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567378af-ccf2-4647-b5a3-998479023b67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Training Loss: 0.2939, Training Accuracy: 0.8811\n",
            "Epoch 2/5, Training Loss: 0.2806, Training Accuracy: 0.8959\n",
            "Epoch 3/5, Training Loss: 0.2676, Training Accuracy: 0.8980\n",
            "Epoch 4/5, Training Loss: 0.2627, Training Accuracy: 0.8985\n",
            "Epoch 5/5, Training Loss: 0.2544, Training Accuracy: 0.9012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Evaluate on validation set after each epoch or outside the loop\n",
        "\n",
        "model.eval()\n",
        "running_correct_val = 0\n",
        "running_total_val = 0\n",
        "y_true_epoch, y_pred_epoch, y_prob_epoch = [], [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs_val, labels_val in val_loader:\n",
        "        inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
        "        if labels_val.ndim > 1 and labels_val.size(-1) == 1:\n",
        "            labels_val = labels_val.squeeze(-1)\n",
        "\n",
        "        outputs_val = model(inputs_val)\n",
        "        probs_val = torch.softmax(outputs_val, dim=1)\n",
        "        _, predicted_val = torch.max(outputs_val, 1)\n",
        "\n",
        "        y_true_epoch.extend(labels_val.cpu().numpy())\n",
        "        y_pred_epoch.extend(predicted_val.cpu().numpy())\n",
        "\n",
        "        # FIX: Append ONLY the class-1 (pneumonia) probs\n",
        "        pneumonia_probs = probs_val[:, 1].cpu().numpy()  # shape: (batch_size,)\n",
        "        y_prob_epoch.extend(pneumonia_probs.tolist())\n",
        "\n",
        "        running_total_val += labels_val.size(0)\n",
        "        running_correct_val += (predicted_val == labels_val).sum().item()\n",
        "\n",
        "# Collect probabilities for the positive class (class 1 = pneumonia)\n",
        "if num_classes > 1:\n",
        "    positive_class_label_name = 'pneumonia'\n",
        "    positive_class_idx = -1\n",
        "    for idx, name in info['label'].items():\n",
        "        if name.lower() == positive_class_label_name:\n",
        "            positive_class_idx = int(idx)\n",
        "            break\n",
        "\n",
        "    if positive_class_idx != -1:\n",
        "        y_prob_epoch.extend(probs_val[:, positive_class_idx].cpu().numpy())\n",
        "    else:\n",
        "        print(f\"Warning: Label '{positive_class_label_name}' not found in dataset info.\")\n",
        "        y_prob_epoch.extend(probs_val[:, 1].cpu().numpy())  # Default to class 1\n",
        "else:\n",
        "    y_prob_epoch.extend(probs_val[:, 0].cpu().numpy())\n",
        "\n",
        "# --------------------------\n",
        "# Calculate validation metrics\n",
        "epoch_val_acc = running_correct_val / running_total_val\n",
        "print(f\"Validation Accuracy: {epoch_val_acc:.4f}\")\n",
        "\n",
        "# Ensure all lists are the same length\n",
        "min_len = min(len(y_true_epoch), len(y_pred_epoch), len(y_prob_epoch))\n",
        "y_true_epoch = y_true_epoch[:min_len]\n",
        "y_pred_epoch = y_pred_epoch[:min_len]\n",
        "y_prob_epoch = y_prob_epoch[:min_len]\n",
        "\n",
        "# Calculate metrics if validation set has more than one class\n",
        "if num_classes > 1 and len(set(y_true_epoch)) > 1:\n",
        "    try:\n",
        "        # Re-find the positive class index in case it's needed\n",
        "        positive_class_label_name = 'pneumonia'\n",
        "        positive_class_idx = -1\n",
        "        for idx, name in info['label'].items():\n",
        "            if name.lower() == positive_class_label_name:\n",
        "                positive_class_idx = int(idx)\n",
        "                break\n",
        "\n",
        "        if positive_class_idx != -1:\n",
        "            val_f1 = f1_score(y_true_epoch, y_pred_epoch, average='binary', pos_label=positive_class_idx)\n",
        "            val_auc = roc_auc_score(y_true_epoch, y_prob_epoch)\n",
        "            print(f\"Validation F1 Score: {val_f1:.4f}, Validation AUC: {val_auc:.4f}\")\n",
        "        else:\n",
        "            print(f\"Could not calculate validation metrics: Label '{positive_class_label_name}' not found in dataset info.\")\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Could not calculate validation metrics: {e}. This can happen if only one class is present in the validation batch for binary metrics.\")\n",
        "else:\n",
        "    print(\"Only one class present in validation set — skipping F1 and AUC.\")\n",
        "\n",
        "# Evaluation on Validation Set (Final)\n",
        "print(\"\\nFinal Validation Results:\")\n",
        "model.eval()\n",
        "y_true_val_final, y_pred_val_final, y_prob_val_final = [], [], []\n",
        "with torch.no_grad():\n",
        "    # Indent the following lines\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # Squeeze validation labels as well for final evaluation\n",
        "        if labels.ndim > 1 and labels.size(-1) == 1:\n",
        "            labels = labels.squeeze(-1)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1)\n",
        "        y_true_val_final.extend(labels.cpu().numpy())\n",
        "        y_pred_val_final.extend(preds.cpu().numpy())\n",
        "        if num_classes > 1:\n",
        "            positive_class_label_name = 'pneumonia'\n",
        "            positive_class_idx = -1\n",
        "            for idx, name in info['label'].items():\n",
        "                if name.lower() == positive_class_label_name:\n",
        "                    # Convert the string index to an integer\n",
        "                    positive_class_idx = int(idx)\n",
        "                    break\n",
        "            if positive_class_idx != -1:\n",
        "                 y_prob_val_final.extend(probs[:, positive_class_idx].cpu().numpy())\n",
        "\n",
        "\n",
        "# Calculate final validation metrics\n",
        "if num_classes > 1 and len(set(y_true_val_final)) > 1:\n",
        "    try:\n",
        "        positive_class_label_name = 'pneumonia'\n",
        "        positive_class_idx = -1\n",
        "        for idx, name in info['label'].items():\n",
        "             if name.lower() == positive_class_label_name:\n",
        "                 # Convert the string index to an integer\n",
        "                 positive_class_idx = int(idx)\n",
        "                 break\n",
        "\n",
        "        if positive_class_idx != -1:\n",
        "             print(\"F1 Score:\", f1_score(y_true_val_final, y_pred_val_final, average='binary', pos_label=positive_class_idx))\n",
        "             print(\"AUC:\", roc_auc_score(y_true_val_final, y_prob_val_final))\n",
        "        else:\n",
        "             print(f\"Could not calculate final validation metrics: Label '{positive_class_label_name}' not found in dataset info.\")\n",
        "    except ValueError as e:\n",
        "         print(f\"Could not calculate final validation metrics: {e}\")\n",
        "else:\n",
        "    print(\"Cannot calculate F1 and AUC for validation set (less than 2 classes or only one class in true labels).\")\n",
        "\n",
        "\n",
        "# Evaluation on Test Set\n",
        "print(\"\\nTest Results:\")\n",
        "model.eval()\n",
        "y_true_test, y_pred_test, y_prob_test = [], [], []\n",
        "with torch.no_grad():\n",
        "    # Indent the following lines\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # Squeeze test labels as well\n",
        "        if labels.ndim > 1 and labels.size(-1) == 1:\n",
        "            labels = labels.squeeze(-1)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1)\n",
        "        y_true_test.extend(labels.cpu().numpy())\n",
        "        y_pred_test.extend(preds.cpu().numpy())\n",
        "        if num_classes > 1:\n",
        "            positive_class_label_name = 'pneumonia'\n",
        "            positive_class_idx = -1\n",
        "            for idx, name in info['label'].items():\n",
        "                if name.lower() == positive_class_label_name:\n",
        "                    # Convert the string index to an integer\n",
        "                    positive_class_idx = int(idx)\n",
        "                    break\n",
        "\n",
        "            if positive_class_idx != -1:\n",
        "                y_prob_test.extend(probs[:, positive_class_idx].cpu().numpy())\n",
        "\n",
        "\n",
        "# Calculate test metrics\n",
        "if num_classes > 1 and len(set(y_true_test)) > 1:\n",
        "    try:\n",
        "        positive_class_label_name = 'pneumonia'\n",
        "        positive_class_idx = -1\n",
        "        for idx, name in info['label'].items():\n",
        "            if name.lower() == positive_class_label_name:\n",
        "                # Convert the string index to an integer\n",
        "                positive_class_idx = int(idx)\n",
        "                break\n",
        "\n",
        "        if positive_class_idx != -1:\n",
        "             print(\"F1 Score:\", f1_score(y_true_test, y_pred_test, average='binary', pos_label=positive_class_idx))\n",
        "             print(\"AUC:\", roc_auc_score(y_true_test, y_prob_test))\n",
        "        else:\n",
        "             print(f\"Could not calculate test metrics: Label '{positive_class_label_name}' not found in dataset info.\")\n",
        "\n",
        "    except ValueError as e:\n",
        "         print(f\"Could not calculate test metrics: {e}\")\n",
        "else:\n",
        "     print(\"Cannot calculate F1 and AUC for test set (less than 2 classes or only one class in true labels).\")"
      ],
      "metadata": {
        "id": "k2H5KpY-IbXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6be7623-000b-45c2-9230-d566cad6a56b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8950\n",
            "Validation F1 Score: 0.9308, Validation AUC: 0.9564\n",
            "\n",
            "Final Validation Results:\n",
            "F1 Score: 0.9308176100628931\n",
            "AUC: 0.9564314957631154\n",
            "\n",
            "Test Results:\n",
            "F1 Score: 0.8741418764302059\n",
            "AUC: 0.9264409379793995\n"
          ]
        }
      ]
    }
  ]
}